{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "import random\n",
    "import math \n",
    "min_val_loss=100\n",
    "\n",
    "dict = {'user_id':[1,1,1,2,2,3,4,4,4,5] ,\n",
    "        'meme_id': [1,2,3,1,3,2,1,2,3,3],\n",
    "        'user_meme_interaction':['like', 'dislike', 'rofl', 'like','like', 'dislike', 'rofl', 'like','like', 'dislike']} \n",
    "  \n",
    "df = pd.DataFrame(dict) \n",
    "dict1={'like':1, 'dislike':-1, 'rofl':5}\n",
    "\n",
    "def rating_fn(reaction):\n",
    "    return dict1[reaction]\n",
    "\n",
    "df['rating']=df['user_meme_interaction'].apply(rating_fn)\n",
    "ratings=df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_col(col, train_col=None):\n",
    "    \"\"\"Encodes a pandas column with continous ids. \n",
    "    \"\"\"\n",
    "    if train_col is not None:\n",
    "        uniq = train_col.unique()\n",
    "    else:\n",
    "        uniq = col.unique()\n",
    "    name2idx = {o:i for i,o in enumerate(uniq)}\n",
    "    return name2idx, np.array([name2idx.get(x, -1) for x in col]), len(uniq)\n",
    "\n",
    "def encode_data(df, train=None):\n",
    "    \"\"\" Encodes rating data with continous user and movie ids. \n",
    "    If train is provided, encodes df with the same encoding as train.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    for col_name in [\"user_id\", \"meme_id\"]:\n",
    "        train_col = None\n",
    "        if train is not None:\n",
    "            train_col = train[col_name]\n",
    "        _,col,_ = proc_col(df[col_name], train_col)\n",
    "        df[col_name] = col\n",
    "        df = df[df[col_name] >= 0]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df=ratings\n",
    "# train_df = encode_data(train_df)\n",
    "# train_df=train_df[['user_id', 'meme_id', 'rating']]\n",
    "# train_df = train_df.astype('int32',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_Dataset(data.Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.length = len(df)\n",
    "        self.y = torch.FloatTensor(df['rating'].values)\n",
    "        self.x = torch.LongTensor(df.drop('rating',axis=1).values)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        sample = {'x':self.x[index], 'y':self.y[index]}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollabFNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, emb_size=100, n_hidden=500):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(num_users, emb_size), nn.Embedding(num_items, emb_size)])\n",
    "        self.lin1 = nn.Linear(emb_size*2, n_hidden)\n",
    "        self.lin2 = nn.Linear(n_hidden, 1)\n",
    "        self.drop1 = nn.Dropout(0.1)\n",
    "        self.drop2 = nn.Dropout(0.2)\n",
    "        self.bn1 = nn.BatchNorm1d(emb_size*2)\n",
    "        self.bn2 = nn.BatchNorm1d(n_hidden)\n",
    "        \n",
    "    def forward(self, u, v):\n",
    "        U = self.embs[0](u)\n",
    "        V = self.embs[1](v)\n",
    "        x = self.bn1(torch.cat([U, V], dim=1))\n",
    "        x = F.relu(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(self.bn2(x))\n",
    "        x = self.drop2(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(model, lr = 0.01, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch.optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "        \n",
    "def train(model, epochs, train_dl, device, actual_y, lrs=None, verbose=False):\n",
    "    idx=0\n",
    "    for i in range(epochs): \n",
    "        model.train()\n",
    "        total = 0\n",
    "        sum_loss = 0\n",
    "        for sample in train_dl:\n",
    "            optim = get_optimizer(model, lr = lrs[idx], wd = 0.00001)\n",
    "            x = sample['x'].to(device)\n",
    "            y = sample['y'].unsqueeze(1).to(device)\n",
    "            batch = y.shape[0]\n",
    "            y_hat = model(x[:,0], x[:,1])\n",
    "            \n",
    "            loss = F.mse_loss(y_hat, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            total += batch\n",
    "            sum_loss += batch*(loss.item())\n",
    "            if verbose: print(sum_loss/total)\n",
    "#         print(\"train loss \", sum_loss/total)\n",
    "        \n",
    "    return val_loss(model, train_dl, device, actual_y)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def val_loss(model, valid_dl, device, actual_y):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for sample in valid_dl:\n",
    "        x = sample['x'].to(device)\n",
    "        y = sample['y'].unsqueeze(1).to(device)\n",
    "        batch = y.shape[0]\n",
    "        y_hat = model(x[:,0], x[:,1])\n",
    "        loss = F.mse_loss(y_hat, y)\n",
    "        sum_loss += batch*(loss.item())\n",
    "        total += batch\n",
    "        \n",
    "        global min_val_loss\n",
    "        global final_scores\n",
    "                \n",
    "        input_list=y.cpu().detach().numpy()\n",
    "        tensor_y=np.concatenate(input_list).ravel()\n",
    "        input_list1=y_hat.cpu().detach().numpy()\n",
    "        predicted_y=np.concatenate(input_list1).ravel()\n",
    "        scores=rearrange(actual_y.tolist(),tensor_y.tolist(), predicted_y.tolist())\n",
    "    val_loss=sum_loss/total\n",
    "    min_val_loss=min(min_val_loss,val_loss)\n",
    "    if min_val_loss==val_loss:\n",
    "        final_scores=scores\n",
    "#     print(final_scores, val_loss)\n",
    "    return final_scores\n",
    "\n",
    "\n",
    "def sltr(num_epochs, train_size, eta_max=0.01, cut_frac=0.1, ratio=32):\n",
    "    '''Slanted triangular learning rates written from ULMFiT paper\n",
    "        see [ULMFit](https://arxiv.org/abs/1801.06146)\n",
    "    '''\n",
    "    training_iterations = num_epochs * train_size\n",
    "    cut = math.floor(training_iterations * cut_frac)\n",
    "    lr = [None for _ in range(training_iterations)]\n",
    "    for t in range(training_iterations):\n",
    "        if t<cut: \n",
    "            p=t/cut\n",
    "        else: \n",
    "            p=1-((t-cut)/(cut*(1/cut_frac-1)))\n",
    "        lr[t] = eta_max * (1+p*(ratio-1))/ratio\n",
    "    return lr\n",
    "\n",
    "def learning_rate_range(model, train_dl, device, lr_high=0.1, epochs=2):\n",
    "    save_model(model, str(PATH/\"model_tmp.pth\"))\n",
    "    losses = []\n",
    "    iterations = len(train_dl) * epochs\n",
    "    delta = (lr_high / iterations)\n",
    "    lrs = [i*delta for i in range(iterations)]\n",
    "    model.train()\n",
    "    ind = 0\n",
    "    for i in range(epochs):\n",
    "        for sample in train_dl:\n",
    "            optim = get_optimizer(model, lr=lrs[ind])\n",
    "            y = sample['y'].unsqueeze(1).to(device)\n",
    "            x = sample['x'].to(device)\n",
    "            batch = y.shape[0]\n",
    "            y_hat = model(x[:,0],x[:,1])\n",
    "            loss = F.mse_loss(y_hat, y)\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            losses.append(loss.item())\n",
    "            ind+=1\n",
    "    load_model(model, str(PATH/\"model_tmp.pth\"))\n",
    "    return lrs, losses\n",
    "\n",
    "def save_model(model, location):\n",
    "    torch.save(model.state_dict(), location)\n",
    "\n",
    "def load_model(model, location):\n",
    "    model.load_state_dict(torch.load(location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange(actual_y,tensr_y,predicted_tensor_y):\n",
    "    rearranged_y=[]\n",
    "    for i in range(len(tensr_y)):\n",
    "        element=actual_y[i]\n",
    "        idx=tensr_y.index(element)\n",
    "        rearranged_y=np.append(rearranged_y, predicted_tensor_y[idx])\n",
    "    return rearranged_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list=get_collab_score(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_score(df, user_id, meme_id, score_list):\n",
    "    \n",
    "    df1=df[df['user_id'] == user_id]\n",
    "    idx=df1[df1['meme_id'] == meme_id].index[0]\n",
    "    return score_list[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27975428104400635"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_score(df,1,1,score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.27975428, -0.21466146,  0.52837431,  0.27975428,  0.27975428,\n",
       "       -0.21466146,  0.52837431,  0.27975428,  0.27975428, -0.21466146])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
